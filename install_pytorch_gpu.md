# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å GPU –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π (CUDA)

## –î–ª—è RTX 2060 Super

–í–∞—à–∞ –∫–∞—Ä—Ç–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç CUDA Compute Capability 7.5, —á—Ç–æ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å CUDA 11.8 –∏ 12.1.

## –í–∞—Ä–∏–∞–Ω—Ç 1: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```bash
cd apps/client

# –°–æ–∑–¥–∞–π—Ç–µ —Å–∫—Ä–∏–ø—Ç (–µ—Å–ª–∏ –Ω–∞ Linux/Mac)
bash install_pytorch_gpu.sh

# –ò–ª–∏ –≤—Ä—É—á–Ω—É—é (Windows/Linux/Mac)
pip install install_pytorch_gpu.txt
```

## –í–∞—Ä–∏–∞–Ω—Ç 2: –†—É—á–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

### –®–∞–≥ 1: –£–¥–∞–ª–∏—Ç—å CPU-–≤–µ—Ä—Å–∏—é

```bash
pip uninstall torch torchvision torchaudio -y
```

### –®–∞–≥ 2: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å GPU-–≤–µ—Ä—Å–∏—é

**–î–ª—è CUDA 11.8 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è):**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**–î–ª—è CUDA 12.1 (–µ—Å–ª–∏ CUDA 12.x —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞):**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### –®–∞–≥ 3: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —É—Å—Ç–∞–Ω–æ–≤–∫—É

```bash
python check_gpu.py
```

–î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å:
```
[OK] CUDA available: YES
[OK] CUDA version: 11.8 (–∏–ª–∏ 12.1)
[OK] GPU 0: NVIDIA GeForce RTX 2060 SUPER
     Memory: 8.00 GB
```

## –í–∞—Ä–∏–∞–Ω—Ç 3: –° –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º requirements

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `requirements_gpu.txt`:

```
# PyTorch —Å CUDA 11.8
torch==2.1.2+cu118
torchvision==0.16.2+cu118
torchaudio==2.1.2+cu118
--extra-index-url https://download.pytorch.org/whl/cu118

# –û—Å—Ç–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
fastapi
uvicorn
pydantic
pydantic-settings
```

–£—Å—Ç–∞–Ω–æ–≤–∫–∞:
```bash
pip install -r requirements_gpu.txt
```

## –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA Toolkit (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

–ï—Å–ª–∏ —É –≤–∞—Å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω CUDA Toolkit:

### Windows:
1. –°–∫–∞—á–∞–π—Ç–µ [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-11-8-0-download-archive)
2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ (—Ç—Ä–µ–±—É–µ—Ç ~3GB –º–µ—Å—Ç–∞)
3. –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ –∫–æ–º–ø—å—é—Ç–µ—Ä

### Linux:
```bash
# Ubuntu/Debian
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sudo sh cuda_11.8.0_520.61.05_linux.run
```

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ**: PyTorch –≤–∫–ª—é—á–∞–µ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ CUDA –±–∏–±–ª–∏–æ—Ç–µ–∫–∏, –ø–æ—ç—Ç–æ–º—É —É—Å—Ç–∞–Ω–æ–≤–∫–∞ CUDA Toolkit –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞ –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.

## –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–æ–≤ NVIDIA

```bash
# Windows
nvidia-smi

# Linux
nvidia-smi
```

–î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å:
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 5xx.xx       Driver Version: 5xx.xx       CUDA Version: 11.x  |
|-------------------------------+----------------------+----------------------+
| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce RTX 206... WDDM  | 00000000:01:00.0  On |                  N/A |
| 30%   40C    P8    15W / 175W |    500MB /  8192MB   |      0%      Default |
+-------------------------------+----------------------+----------------------+
```

## Troubleshooting

### "CUDA not available" –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏

1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–µ—Ä—Å–∏—é PyTorch:
```bash
python -c "import torch; print(torch.__version__)"
```
–î–æ–ª–∂–Ω–æ –±—ã—Ç—å: `2.1.2+cu118` (–Ω–µ `2.1.2+cpu`)

2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ CUDA:
```bash
python -c "import torch; print(torch.cuda.is_available())"
```
–î–æ–ª–∂–Ω–æ –±—ã—Ç—å: `True`

3. –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ:
```bash
pip cache purge
pip uninstall torch torchvision torchaudio -y
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### "Out of memory" –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è

–£–º–µ–Ω—å—à–∏—Ç–µ `batch_size` –≤ `config.py`:
```python
batch_size: int = 16  # –≤–º–µ—Å—Ç–æ 32
```

–ò–ª–∏:
```python
batch_size: int = 8   # –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π
```

### GPU –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏:
```bash
python fl_train_simple.py
```

–î–æ–ª–∂–Ω–æ –±—ã—Ç—å:
```
Using device: cuda
```

–ï—Å–ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç `cpu`, –∑–Ω–∞—á–∏—Ç CUDA –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞.

## –ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏

1. **–ü—Ä–æ–≤–µ—Ä—å—Ç–µ GPU**:
```bash
python check_gpu.py
```

2. **–ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ**:
```bash
python fl_train_simple.py
```

3. **–ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ GPU**:
–í –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ:
```bash
# Windows/Linux
nvidia-smi -l 1  # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É
```

–í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –≤—ã —É–≤–∏–¥–∏—Ç–µ:
- GPU-Util: 90-100% (–∑–∞–≥—Ä—É–∑–∫–∞ GPU)
- Memory-Usage: —É–≤–µ–ª–∏—á–∏—Ç—Å—è –Ω–∞ 500-2000MB
- Temp: –ø–æ–≤—ã—Å–∏—Ç—Å—è –¥–æ 60-75¬∞C

## –û–∂–∏–¥–∞–µ–º–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ

–î–ª—è RTX 2060 Super (8GB VRAM):
- **CPU**: ~1-2 —Å–µ–∫—É–Ω–¥—ã –Ω–∞ —ç–ø–æ—Ö—É (17 —Å–≤–∞–π–ø–æ–≤)
- **GPU**: ~0.1-0.3 —Å–µ–∫—É–Ω–¥—ã –Ω–∞ —ç–ø–æ—Ö—É (10-20x –±—ã—Å—Ç—Ä–µ–µ)

–î–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ (1000+ —Å–≤–∞–π–ø–æ–≤):
- **CPU**: 30-60 —Å–µ–∫—É–Ω–¥ –Ω–∞ —ç–ø–æ—Ö—É
- **GPU**: 2-5 —Å–µ–∫—É–Ω–¥ –Ω–∞ —ç–ø–æ—Ö—É

## –ü–æ–ª–µ–∑–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
python check_gpu.py

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU
nvidia-smi -l 1

# –ü—Ä–æ–≤–µ—Ä–∫–∞ PyTorch
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}')"

# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ GPU
python fl_train_simple.py

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
python -c "import torch; print(f'Memory allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB')"
```

## –ì–æ—Ç–æ–≤–æ!

–ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å–∫–∞–π—Ç–µ:
```bash
python fl_train_simple.py
```

–°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç GPU –∏ –±—É–¥–µ—Ç –æ–±—É—á–∞—Ç—å –Ω–∞ –Ω–µ–º! üöÄ

